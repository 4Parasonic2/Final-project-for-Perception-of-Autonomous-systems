{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faed3ada",
   "metadata": {},
   "source": [
    "# Goal 3: Calibration and Rectification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7bde88",
   "metadata": {},
   "source": [
    "### Step #01: Load images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4328c803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "557fe7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Constants\n",
    "# ---------------------------------------------------------------------------\n",
    "RELATIVE_RAW_DATASET_PATH = \"../raw\"\n",
    "LEFT_IMG_PATH  = f\"{RELATIVE_RAW_DATASET_PATH}/calib/image_02/data\"\n",
    "RIGHT_IMG_PATH = f\"{RELATIVE_RAW_DATASET_PATH}/calib/image_03/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e4f6f465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Board definitions\n",
    "boards = [\n",
    "    {\"name\": \"boardBig\", \"pattern_size\": (11,7)},\n",
    "    {\"name\": \"boardMed\", \"pattern_size\": (5,7)},\n",
    "]\n",
    "\n",
    "# VISUALIZATION SETTINGS\n",
    "VISUALIZE = True\n",
    "VIS_DELAY_MS = 0  # Wait 500ms between images. Set to 0 to wait for keypress.\n",
    "\n",
    "# !!! CRITICAL !!! \n",
    "# Measure your real square size. \n",
    "# USE METERS to match KITTI format (e.g., 30mm = 0.03)\n",
    "REAL_SQUARE_SIZE_M = 0.1\n",
    "\n",
    "# Precompute object point templates\n",
    "obj_templates = {}\n",
    "for b in boards:\n",
    "    nx, ny = b[\"pattern_size\"]\n",
    "    # We apply the real world scale here\n",
    "    objp = np.zeros((nx*ny, 3), np.float32)\n",
    "    objp[:, :2] = np.mgrid[0:nx, 0:ny].T.reshape(-1, 2) * REAL_SQUARE_SIZE_M\n",
    "    obj_templates[b[\"name\"]] = objp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41313692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19 left images.\n",
      "[00] 0000000000.png | Found 12 boards\n",
      "\n",
      "============================================================\n",
      "  PHASE 1: INITIAL CALIBRATION (12 detections)\n",
      "============================================================\n",
      "Initial RMS: 0.1974 px\n",
      "\n",
      "============================================================\n",
      "  PHASE 2: FILTERING OUTLIERS\n",
      "============================================================\n",
      "Original Avg Reprojection Error: 0.0305 px\n",
      "Dropped 0 detections with error > 0.5 px\n",
      "Remaining detections: 12\n",
      "\n",
      ">>> Re-calibrating with refined dataset...\n",
      "Final Refined RMS: 0.1974 px\n",
      "K (Intrinsics):\n",
      "[[1108.84    0.    692.86]\n",
      " [   0.   1093.94  255.46]\n",
      " [   0.      0.      1.  ]]\n",
      "D (Distortion):\n",
      "[[-0.095 -0.083 -0.002 -0.012  0.176  0.106  0.09  -0.1    0.     0.\n",
      "   0.     0.     0.     0.   ]]\n",
      "\n",
      "============================================================\n",
      "  VISUALIZING RESULT\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 268\u001b[0m\n\u001b[1;32m    264\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mputText(preview, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMS: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret_final\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m), cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m1\u001b[39m, (\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m255\u001b[39m,\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    266\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLeft: Raw vs Undistorted\u001b[39m\u001b[38;5;124m\"\u001b[39m, preview)\n\u001b[0;32m--> 268\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m27\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m \u001b[38;5;66;03m# ESC\u001b[39;00m\n\u001b[1;32m    271\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 1. CONFIGURATION\n",
    "# ---------------------------------------------------------------------------\n",
    "RELATIVE_RAW_DATASET_PATH = \"../raw\"\n",
    "LEFT_IMG_PATH  = f\"{RELATIVE_RAW_DATASET_PATH}/calib/image_02/data\"\n",
    "\n",
    "PROCESS_ALL_IMAGES = False  \n",
    "\n",
    "# Visualization settings\n",
    "DEBUG_VISUALIZE    = True \n",
    "VISUALIZE_DELAY    = 1\n",
    "\n",
    "MIN_BOARD_WIDTH_PX = 25\n",
    "\n",
    "# RMS IMPROVEMENT CONFIG\n",
    "REJECTION_THRESH_PX = 0.5  # Throw away detections with error > 0.5 px\n",
    "ENABLE_RATIONAL_MODEL = True # Set True if you have a very wide lens (adds k4, k5, k6)\n",
    "\n",
    "# WARNING: Measure your physical boards! If one is printed at 95% scale, \n",
    "# your RMS will never go down.\n",
    "boards = [\n",
    "    {\"name\": \"boardBig\", \"pattern_size\": (11, 7), \"square_size\": 0.10},\n",
    "    {\"name\": \"boardMed\", \"pattern_size\": (5, 7),  \"square_size\": 0.10}, \n",
    "]\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 2. DETECTION LOGIC\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def get_image_files(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        return []\n",
    "    files = sorted(glob.glob(os.path.join(directory, \"*.png\")))\n",
    "    if not files:\n",
    "        files = sorted(glob.glob(os.path.join(directory, \"*.jpg\")))\n",
    "    return files\n",
    "\n",
    "def sharpen_image(gray_img):\n",
    "    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
    "    return cv2.filter2D(gray_img, -1, kernel)\n",
    "\n",
    "def detect_multiple_boards(img):\n",
    "    gray_base = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray_processing = sharpen_image(gray_base).copy()\n",
    "    \n",
    "    # IMPROVEMENT: Tighter criteria (100 iters or 0.0001 epsilon)\n",
    "    subpix_criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.0001)\n",
    "    \n",
    "    detections = []\n",
    "    \n",
    "    # 255 = Searchable area, 0 = Masked (already found)\n",
    "    search_mask = np.ones_like(gray_base, dtype=np.uint8) * 255\n",
    "\n",
    "    for board in boards:\n",
    "        name = board[\"name\"]\n",
    "        nx, ny = board[\"pattern_size\"]\n",
    "        sq_size = board[\"square_size\"]\n",
    "        \n",
    "        max_instances = 15 \n",
    "        count = 0\n",
    "        \n",
    "        while count < max_instances:\n",
    "            # 1. Apply the mask\n",
    "            masked_input = cv2.bitwise_and(gray_processing, gray_processing, mask=search_mask)\n",
    "\n",
    "            flags = cv2.CALIB_CB_ADAPTIVE_THRESH | cv2.CALIB_CB_NORMALIZE_IMAGE \n",
    "            found, corners = cv2.findChessboardCorners(masked_input, (nx, ny), None)\n",
    "\n",
    "            # 2. Upscaling attempt for small boards\n",
    "            if not found:\n",
    "                gray_up = cv2.resize(masked_input, None, fx=2.0, fy=2.0, interpolation=cv2.INTER_LINEAR)\n",
    "                found_up, corners_up = cv2.findChessboardCorners(gray_up, (nx, ny), None)\n",
    "                if found_up:\n",
    "                    corners = (corners_up / 2.0).astype(np.float32)\n",
    "                    found = True\n",
    "\n",
    "            if not found:\n",
    "                break \n",
    "\n",
    "            corners = corners.reshape(-1, 2).astype(np.float32)\n",
    "            \n",
    "            # 3. Size Check\n",
    "            x,y,w,h = cv2.boundingRect(corners.astype(np.int32))\n",
    "            if w < MIN_BOARD_WIDTH_PX or h < MIN_BOARD_WIDTH_PX:\n",
    "                hull_pts = cv2.convexHull(corners.reshape(-1, 2).astype(np.int32))\n",
    "                cv2.fillConvexPoly(search_mask, hull_pts, 0)\n",
    "                continue\n",
    "\n",
    "            # 4. IMPROVEMENT: Dynamic Subpixel Window Size\n",
    "            # Calculate average distance between the first two corners\n",
    "            dist = np.linalg.norm(corners[0] - corners[1])\n",
    "            radius = int(dist / 2.5) \n",
    "            \n",
    "            # Clamp constraints (min 3px, max 30px to prevent running away)\n",
    "            radius = max(3, min(30, radius))\n",
    "            win_size = (radius, radius)\n",
    "            \n",
    "            cv2.cornerSubPix(gray_base, corners, win_size, (-1, -1), subpix_criteria)\n",
    "\n",
    "            detections.append({\n",
    "                'name': name,\n",
    "                'corners': corners.copy(),\n",
    "                'pattern_size': (nx, ny),\n",
    "                'square_size': sq_size,\n",
    "                'debug_radius': radius # Storing for curiosity\n",
    "            })\n",
    "\n",
    "            # 5. Update Mask\n",
    "            hull_pts = cv2.convexHull(corners.reshape(-1, 2).astype(np.int32))\n",
    "            cv2.fillConvexPoly(search_mask, hull_pts, 0)\n",
    "            search_mask = cv2.erode(search_mask, np.ones((10,10), np.uint8)) \n",
    "            \n",
    "            count += 1\n",
    "\n",
    "    return detections\n",
    "\n",
    "def get_object_points(nx, ny, square_size):\n",
    "    objp = np.zeros((ny * nx, 3), np.float32)\n",
    "    objp[:, :2] = np.mgrid[0:nx, 0:ny].T.reshape(-1, 2)\n",
    "    return objp * square_size\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 3. MAIN EXECUTION\n",
    "# ---------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    left_files = get_image_files(LEFT_IMG_PATH)\n",
    "\n",
    "    objpoints_L = []\n",
    "    imgpoints_L = []\n",
    "    \n",
    "    # Keeping track of which image produced which detection for debugging\n",
    "    det_indices = [] \n",
    "    \n",
    "    img_shape = None\n",
    "\n",
    "    print(f\"Found {len(left_files)} left images.\")\n",
    "    \n",
    "    # --- A. GATHER DATA ---\n",
    "    for i, f_left in enumerate(left_files):\n",
    "        imgL = cv2.imread(f_left)\n",
    "        if imgL is not None:\n",
    "            if img_shape is None: img_shape = (imgL.shape[1], imgL.shape[0])\n",
    "            \n",
    "            detsL = detect_multiple_boards(imgL)\n",
    "            \n",
    "            for det in detsL:\n",
    "                nx, ny = det['pattern_size']\n",
    "                objpoints_L.append(get_object_points(nx, ny, det['square_size']))\n",
    "                imgpoints_L.append(det['corners'])\n",
    "                det_indices.append(i) # Track that this detection belongs to image 'i'\n",
    "\n",
    "            print(f\"[{i:02d}] {os.path.basename(f_left)} | Found {len(detsL)} boards\")\n",
    "\n",
    "            if DEBUG_VISUALIZE and len(detsL) > 0:\n",
    "                vis = imgL.copy()\n",
    "                for det in detsL:\n",
    "                    color = (0, 255, 0) if det['name'] == \"boardBig\" else (0, 0, 255)\n",
    "                    cv2.drawChessboardCorners(vis, det['pattern_size'], det['corners'], True)\n",
    "                    cx, cy = np.mean(det['corners'], axis=0).ravel()\n",
    "                    # Visualize the calculated subpixel window radius\n",
    "                    text = f\"{det['name']} r:{det['debug_radius']}\"\n",
    "                    cv2.putText(vis, text, (int(cx), int(cy)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "                cv2.imshow(\"Debug Detection\", cv2.resize(vis, None, fx=0.6, fy=0.6))\n",
    "                cv2.waitKey(VISUALIZE_DELAY)\n",
    "        else:\n",
    "            print(f\"[{i:02d}] Failed to read {f_left}\")\n",
    "\n",
    "        if not PROCESS_ALL_IMAGES: break\n",
    "\n",
    "    if len(objpoints_L) == 0: \n",
    "        print(\"No detections found.\")\n",
    "        exit()\n",
    "\n",
    "    # --- B. INITIAL CALIBRATION ---\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"  PHASE 1: INITIAL CALIBRATION ({len(objpoints_L)} detections)\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    calib_flags = cv2.CALIB_FIX_K3\n",
    "    if ENABLE_RATIONAL_MODEL:\n",
    "        calib_flags = cv2.CALIB_RATIONAL_MODEL\n",
    "\n",
    "    retL, K1, D1, rvecs1, tvecs1 = cv2.calibrateCamera(\n",
    "        objpoints_L, imgpoints_L, img_shape, None, None, flags=calib_flags\n",
    "    )\n",
    "    print(f\"Initial RMS: {retL:.4f} px\")\n",
    "\n",
    "    # --- C. OUTLIER REJECTION ---\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"  PHASE 2: FILTERING OUTLIERS\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    objpoints_refined = []\n",
    "    imgpoints_refined = []\n",
    "    \n",
    "    errors = []\n",
    "    dropped_count = 0\n",
    "\n",
    "    for i in range(len(objpoints_L)):\n",
    "        # Project points back to image plane\n",
    "        img_points_reproj, _ = cv2.projectPoints(objpoints_L[i], rvecs1[i], tvecs1[i], K1, D1)\n",
    "        \n",
    "        # FIX: Reshape projected points to match the detected points shape (N, 2)\n",
    "        img_points_reproj = img_points_reproj.reshape(-1, 2)\n",
    "        \n",
    "        # Calculate Euclidean error\n",
    "        error = cv2.norm(imgpoints_L[i], img_points_reproj, cv2.NORM_L2) / len(img_points_reproj)\n",
    "        errors.append(error)\n",
    "\n",
    "        if error < REJECTION_THRESH_PX:\n",
    "            objpoints_refined.append(objpoints_L[i])\n",
    "            imgpoints_refined.append(imgpoints_L[i])\n",
    "        else:\n",
    "            dropped_count += 1\n",
    "\n",
    "    print(f\"Original Avg Reprojection Error: {np.mean(errors):.4f} px\")\n",
    "    print(f\"Dropped {dropped_count} detections with error > {REJECTION_THRESH_PX} px\")\n",
    "    print(f\"Remaining detections: {len(objpoints_refined)}\")\n",
    "    \n",
    "    if len(objpoints_refined) < 5:\n",
    "        print(\"CRITICAL: Too many points dropped. Check if your boards are physically flat or measured correctly.\")\n",
    "        # Fallback to original if we lost too much data\n",
    "        objpoints_refined = objpoints_L\n",
    "        imgpoints_refined = imgpoints_L\n",
    "    \n",
    "    # --- D. FINAL CALIBRATION ---\n",
    "    print(f\"\\n>>> Re-calibrating with refined dataset...\")\n",
    "    ret_final, K_final, D_final, rvecs_final, tvecs_final = cv2.calibrateCamera(\n",
    "        objpoints_refined, imgpoints_refined, img_shape, None, None, flags=calib_flags\n",
    "    )\n",
    "\n",
    "    print(f\"Final Refined RMS: {ret_final:.4f} px\")\n",
    "    print(f\"K (Intrinsics):\\n{np.array_str(K_final, precision=2, suppress_small=True)}\")\n",
    "    print(f\"D (Distortion):\\n{np.array_str(D_final, precision=3, suppress_small=True)}\")\n",
    "\n",
    "    # --- E. UNDISTORTION PREVIEW ---\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"  VISUALIZING RESULT\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    h, w = img_shape\n",
    "    new_K, roi = cv2.getOptimalNewCameraMatrix(K_final, D_final, (w,h), 1, (w,h))\n",
    "\n",
    "    for f_left in left_files:\n",
    "        imgL = cv2.imread(f_left)\n",
    "        if imgL is None: continue\n",
    "\n",
    "        undistL = cv2.undistort(imgL, K_final, D_final, None, new_K)\n",
    "\n",
    "        # Draw grid for visual reference\n",
    "        step = 50\n",
    "        for y in range(0, h, step):\n",
    "            cv2.line(undistL, (0, y), (w, y), (0, 255, 0), 1)\n",
    "            cv2.line(imgL, (0, y), (w, y), (0, 0, 255), 1) \n",
    "\n",
    "        combined = np.hstack((imgL, undistL))\n",
    "        preview = cv2.resize(combined, None, fx=0.5, fy=0.5)\n",
    "        cv2.putText(preview, f\"RMS: {ret_final:.4f}\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "        \n",
    "        cv2.imshow(\"Left: Raw vs Undistorted\", preview)\n",
    "        \n",
    "        key = cv2.waitKey(0)\n",
    "        if key == 27: break # ESC\n",
    "\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

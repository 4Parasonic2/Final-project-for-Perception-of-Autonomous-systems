{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faed3ada",
   "metadata": {},
   "source": [
    "# Goal 3: Calibration and Rectification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7bde88",
   "metadata": {},
   "source": [
    "### Step #01: Load images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4328c803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41313692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 19 image pairs...\n",
      "  Loaded 5/19 pairs...\n",
      "  Loaded 10/19 pairs...\n",
      "  Loaded 15/19 pairs...\n",
      "\n",
      "Total Boards Found: 228\n",
      "\n",
      ">>> Running Mono Calibration (This provides poses for RANSAC)...\n",
      "Mono RMS -> L: 0.220 | R: 0.265\n",
      "\n",
      ">>> Running Fast RANSAC (100 iterations)...\n",
      "  [Iter 0] New Best: 69/228 inliers.\n",
      "  [Iter 2] New Best: 95/228 inliers.\n",
      "  [Iter 3] New Best: 151/228 inliers.\n",
      "  [Iter 26] New Best: 189/228 inliers.\n",
      "\n",
      "RANSAC Complete. Kept 189 boards.\n",
      ">>> Final Optimization using Inliers...\n",
      "\n",
      "FINAL STEREO RMS: 0.3176 px\n",
      "Baseline (T x): -0.5631\n",
      "New Focal Length (fx): 1010.1810\n",
      "\n",
      ">>> Calculating Rectification Transforms...\n",
      "Writing calibration data to calib_cam_to_cam.txt...\n",
      "\n",
      ">>> Visualizing Rectification...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Numeric mode unsupported in the posix collation implementation\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 1. CONFIGURATION\n",
    "# ---------------------------------------------------------------------------\n",
    "RELATIVE_RAW_DATASET_PATH = \"../raw\"\n",
    "LEFT_IMG_PATH  = f\"{RELATIVE_RAW_DATASET_PATH}/calib/image_02/data\"\n",
    "RIGHT_IMG_PATH = f\"{RELATIVE_RAW_DATASET_PATH}/calib/image_03/data\"\n",
    "\n",
    "PROCESS_ALL_IMAGES = True \n",
    "\n",
    "MIN_BOARD_WIDTH_PX = 25\n",
    "Y_MATCH_TOLERANCE  = 20.0 \n",
    "RIGHT_X_OFFSET     = 50 \n",
    "\n",
    "# RANSAC SETTINGS\n",
    "RANSAC_ITERATIONS  = 100    \n",
    "RANSAC_SAMPLE_SIZE = 6      \n",
    "RANSAC_THRESHOLD   = 3.0    \n",
    "\n",
    "boards = [\n",
    "    {\"name\": \"boardBig\", \"pattern_size\": (11, 7), \"square_size\": 0.10},\n",
    "    {\"name\": \"boardMed\", \"pattern_size\": (5, 7),  \"square_size\": 0.10}, \n",
    "    {\"name\": \"boardTall\", \"pattern_size\": (5, 15), \"square_size\": 0.10}\n",
    "]\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 2. HELPER FUNCTIONS\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def get_image_files(directory):\n",
    "    if not os.path.exists(directory): return []\n",
    "    files = sorted(glob.glob(os.path.join(directory, \"*.png\")))\n",
    "    if not files: files = sorted(glob.glob(os.path.join(directory, \"*.jpg\")))\n",
    "    return files\n",
    "\n",
    "def sharpen_image(gray_img):\n",
    "    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
    "    return cv2.filter2D(gray_img, -1, kernel)\n",
    "\n",
    "def force_top_left_start(corners):\n",
    "    if (corners[0][0] + corners[0][1]) > (corners[-1][0] + corners[-1][1]):\n",
    "        return corners[::-1]\n",
    "    return corners\n",
    "\n",
    "def get_object_points(nx, ny, square_size):\n",
    "    objp = np.zeros((ny * nx, 3), np.float32)\n",
    "    objp[:, :2] = np.mgrid[0:nx, 0:ny].T.reshape(-1, 2)\n",
    "    return objp * square_size\n",
    "\n",
    "def save_kitti_format(filename, img_shape, K1, D1, K2, D2, R, T, R1, R2, P1, P2):\n",
    "    \"\"\"\n",
    "    Exports stereo calibration data to KITTI calib_cam_to_cam.txt format.\n",
    "    Maps:\n",
    "      Left Camera  -> 02 (and 00 as grayscale proxy)\n",
    "      Right Camera -> 03 (and 01 as grayscale proxy)\n",
    "    \"\"\"\n",
    "    def to_str(arr):\n",
    "        return \" \".join(f\"{x:.6e}\" for x in arr.flatten())\n",
    "\n",
    "    w, h = img_shape\n",
    "    R_ident = np.eye(3, dtype=np.float64)\n",
    "    T_zero  = np.zeros((3, 1), dtype=np.float64)\n",
    "\n",
    "    # 00 & 02 are Left (Reference), 01 & 03 are Right\n",
    "    cameras = {\n",
    "        \"00\": {\"S\": (w,h), \"K\": K1, \"D\": D1, \"R\": R_ident, \"T\": T_zero, \"R_rect\": R1, \"P_rect\": P1},\n",
    "        \"01\": {\"S\": (w,h), \"K\": K2, \"D\": D2, \"R\": R,       \"T\": T,      \"R_rect\": R2, \"P_rect\": P2},\n",
    "        \"02\": {\"S\": (w,h), \"K\": K1, \"D\": D1, \"R\": R_ident, \"T\": T_zero, \"R_rect\": R1, \"P_rect\": P1},\n",
    "        \"03\": {\"S\": (w,h), \"K\": K2, \"D\": D2, \"R\": R,       \"T\": T,      \"R_rect\": R2, \"P_rect\": P2},\n",
    "    }\n",
    "\n",
    "    calib_time = datetime.now().strftime(\"%d-%b-%Y %H:%M:%S\")\n",
    "    corner_dist = boards[0][\"square_size\"] \n",
    "\n",
    "    print(f\"Writing calibration data to {filename}...\")\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(f\"calib_time: {calib_time}\\n\")\n",
    "        f.write(f\"corner_dist: {corner_dist:.6e}\\n\")\n",
    "        \n",
    "        for cam_id in [\"00\", \"01\", \"02\", \"03\"]:\n",
    "            c = cameras[cam_id]\n",
    "            f.write(f\"S_{cam_id}: {float(c['S'][0]):.6e} {float(c['S'][1]):.6e}\\n\")\n",
    "            f.write(f\"K_{cam_id}: {to_str(c['K'])}\\n\")\n",
    "            f.write(f\"D_{cam_id}: {to_str(c['D'])}\\n\")\n",
    "            f.write(f\"R_{cam_id}: {to_str(c['R'])}\\n\")\n",
    "            f.write(f\"T_{cam_id}: {to_str(c['T'])}\\n\")\n",
    "            f.write(f\"S_rect_{cam_id}: {float(c['S'][0]):.6e} {float(c['S'][1]):.6e}\\n\")\n",
    "            f.write(f\"R_rect_{cam_id}: {to_str(c['R_rect'])}\\n\")\n",
    "            f.write(f\"P_rect_{cam_id}: {to_str(c['P_rect'])}\\n\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 3. DETECTION & MATCHING\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def detect_boards_raw(img):\n",
    "    gray_base = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray_processing = sharpen_image(gray_base).copy()\n",
    "    subpix_criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.0001)\n",
    "    detections = []\n",
    "\n",
    "    for board in boards:\n",
    "        name = board[\"name\"]\n",
    "        nx, ny = board[\"pattern_size\"]\n",
    "        sq_size = board[\"square_size\"]\n",
    "        \n",
    "        while True:\n",
    "            flags = cv2.CALIB_CB_ADAPTIVE_THRESH + cv2.CALIB_CB_NORMALIZE_IMAGE\n",
    "            ret, corners = cv2.findChessboardCorners(gray_processing, (nx, ny), flags)\n",
    "            \n",
    "            if not ret:\n",
    "                gray_upscaled = cv2.resize(gray_processing, None, fx=2.0, fy=2.0, interpolation=cv2.INTER_CUBIC)\n",
    "                ret, corners_up = cv2.findChessboardCorners(gray_upscaled, (nx, ny), flags)\n",
    "                if ret: corners = corners_up / 2.0\n",
    "\n",
    "            if ret:\n",
    "                corners = corners.reshape(-1, 2).astype(np.float32)\n",
    "                x,y,w,h = cv2.boundingRect(corners.astype(np.int32))\n",
    "                if w < MIN_BOARD_WIDTH_PX: \n",
    "                    hull = cv2.convexHull(corners.astype(np.int32))\n",
    "                    cv2.fillConvexPoly(gray_processing, hull, 0)\n",
    "                    continue\n",
    "\n",
    "                dist = np.linalg.norm(corners[0] - corners[1])\n",
    "                radius = max(3, min(30, int(dist / 2.5)))\n",
    "                cv2.cornerSubPix(gray_base, corners, (radius, radius), (-1, -1), subpix_criteria)\n",
    "                \n",
    "                cx, cy = np.mean(corners, axis=0).ravel()\n",
    "                detections.append({\n",
    "                    'name': name, 'centroid': (cx, cy),\n",
    "                    'corners': corners, 'pattern_size': (nx, ny), 'square_size': sq_size\n",
    "                })\n",
    "\n",
    "                mask = np.zeros_like(gray_processing)\n",
    "                hull = cv2.convexHull(corners.astype(np.int32))\n",
    "                cv2.fillConvexPoly(mask, hull, 255)\n",
    "                mask = cv2.dilate(mask, np.ones((15,15), np.uint8))\n",
    "                gray_processing[mask > 0] = 0\n",
    "            else:\n",
    "                break \n",
    "    return detections\n",
    "\n",
    "def match_boards_global(left_dets, right_dets):\n",
    "    potential_matches = []\n",
    "    for l_idx, l_det in enumerate(left_dets):\n",
    "        lx, ly = l_det['centroid']\n",
    "        for r_idx, r_det in enumerate(right_dets):\n",
    "            if l_det['name'] != r_det['name']: continue\n",
    "            rx, ry = r_det['centroid']\n",
    "            rx_shifted = rx + RIGHT_X_OFFSET \n",
    "            dy = abs(ly - ry)\n",
    "            dx = abs(lx - rx_shifted)\n",
    "            if dy > Y_MATCH_TOLERANCE: continue\n",
    "            score = (dy * 2.0) + dx \n",
    "            potential_matches.append({'score': score, 'l_idx': l_idx, 'r_idx': r_idx, 'l_det': l_det, 'r_det': r_det})\n",
    "    potential_matches.sort(key=lambda x: x['score'])\n",
    "    final_matches = []\n",
    "    used_L, used_R = set(), set()\n",
    "    for m in potential_matches:\n",
    "        if m['l_idx'] not in used_L and m['r_idx'] not in used_R:\n",
    "            final_matches.append((m['l_det'], m['r_det']))\n",
    "            used_L.add(m['l_idx'])\n",
    "            used_R.add(m['r_idx'])\n",
    "    return final_matches\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 4. FAST RANSAC LOGIC\n",
    "# ---------------------------------------------------------------------------\n",
    "def check_stereo_consistency(obj_pts, img_pts_R, rvecL, tvecL, K2, D2, R_stereo, T_stereo):\n",
    "    # 1. Transform Object Points to Left Camera Coordinate System\n",
    "    R_mono, _ = cv2.Rodrigues(rvecL)\n",
    "    P_left = (R_mono @ obj_pts.T.astype(np.float64)).T + tvecL.T \n",
    "\n",
    "    # 2. Transform Left Camera Points to Right Camera Coordinate System\n",
    "    P_right = (R_stereo @ P_left.T).T + T_stereo.T\n",
    "\n",
    "    # 3. Project to Right Image Plane\n",
    "    img_pts_proj, _ = cv2.projectPoints(P_right, np.zeros(3), np.zeros(3), K2, D2)\n",
    "    \n",
    "    # Cast to float32 for consistency check\n",
    "    img_pts_proj = img_pts_proj.reshape(-1, 2).astype(np.float32)\n",
    "    \n",
    "    # 4. Calculate Error\n",
    "    error = cv2.norm(img_pts_R, img_pts_proj, cv2.NORM_L2) / np.sqrt(len(img_pts_R))\n",
    "    return error\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 5. MAIN EXECUTION\n",
    "# ---------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    left_files = get_image_files(LEFT_IMG_PATH)\n",
    "    right_files = get_image_files(RIGHT_IMG_PATH)\n",
    "    min_len = min(len(left_files), len(right_files))\n",
    "    \n",
    "    objpoints, imgpoints_L, imgpoints_R = [], [], []\n",
    "    img_shape = None\n",
    "\n",
    "    print(f\"Processing {min_len} image pairs...\")\n",
    "\n",
    "    for i, (f_left, f_right) in enumerate(zip(left_files[:min_len], right_files[:min_len])):\n",
    "        imgL = cv2.imread(f_left)\n",
    "        imgR = cv2.imread(f_right)\n",
    "        if imgL is None or imgR is None: continue\n",
    "        if img_shape is None: img_shape = (imgL.shape[1], imgL.shape[0])\n",
    "\n",
    "        detsL = detect_boards_raw(imgL)\n",
    "        detsR = detect_boards_raw(imgR)\n",
    "        pairs = match_boards_global(detsL, detsR)\n",
    "\n",
    "        for l_det, r_det in pairs:\n",
    "            nx, ny = l_det['pattern_size']\n",
    "            objpoints.append(get_object_points(nx, ny, l_det['square_size']))\n",
    "            imgpoints_L.append(force_top_left_start(l_det['corners']))\n",
    "            imgpoints_R.append(force_top_left_start(r_det['corners']))\n",
    "\n",
    "        if (i+1) % 5 == 0: print(f\"  Loaded {i+1}/{min_len} pairs...\")\n",
    "        if not PROCESS_ALL_IMAGES and i > 0: break\n",
    "\n",
    "    total_boards = len(objpoints)\n",
    "    if total_boards == 0: print(\"No detections.\"); exit()\n",
    "    print(f\"\\nTotal Boards Found: {total_boards}\")\n",
    "\n",
    "    # --- MONO CALIBRATION ---\n",
    "    print(\"\\n>>> Running Mono Calibration (This provides poses for RANSAC)...\")\n",
    "    # Standard model: Fix K3 (radial distortion coefficient 3)\n",
    "    calib_flags = cv2.CALIB_FIX_K3\n",
    "\n",
    "    retL, K1, D1, rvecsL, tvecsL = cv2.calibrateCamera(objpoints, imgpoints_L, img_shape, None, None, flags=calib_flags)\n",
    "    retR, K2, D2, rvecsR, tvecsR = cv2.calibrateCamera(objpoints, imgpoints_R, img_shape, None, None, flags=calib_flags)\n",
    "    print(f\"Mono RMS -> L: {retL:.3f} | R: {retR:.3f}\")\n",
    "\n",
    "    # --- FAST RANSAC STEREO ---\n",
    "    print(f\"\\n>>> Running Fast RANSAC ({RANSAC_ITERATIONS} iterations)...\")\n",
    "    \n",
    "    # Standard model for RANSAC\n",
    "    stereo_flags_fixed = cv2.CALIB_FIX_INTRINSIC | cv2.CALIB_FIX_K3\n",
    "    \n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 1e-4)\n",
    "\n",
    "    best_score = 0 \n",
    "    best_inliers_idx = []\n",
    "    \n",
    "    all_indices = list(range(total_boards))\n",
    "\n",
    "    for it in range(RANSAC_ITERATIONS):\n",
    "        sample_idxs = random.sample(all_indices, RANSAC_SAMPLE_SIZE)\n",
    "        \n",
    "        try:\n",
    "            _, _,_,_,_, R_hyp, T_hyp, _, _ = cv2.stereoCalibrate(\n",
    "                [objpoints[k] for k in sample_idxs], \n",
    "                [imgpoints_L[k] for k in sample_idxs], \n",
    "                [imgpoints_R[k] for k in sample_idxs], \n",
    "                K1, D1, K2, D2, img_shape, criteria=criteria, flags=stereo_flags_fixed\n",
    "            )\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        current_inliers = []\n",
    "        \n",
    "        for k in all_indices:\n",
    "            err = check_stereo_consistency(\n",
    "                objpoints[k], imgpoints_R[k], \n",
    "                rvecsL[k], tvecsL[k], \n",
    "                K2, D2, R_hyp, T_hyp\n",
    "            )\n",
    "            if err < RANSAC_THRESHOLD:\n",
    "                current_inliers.append(k)\n",
    "\n",
    "        count = len(current_inliers)\n",
    "        if count > best_score:\n",
    "            best_score = count\n",
    "            best_inliers_idx = current_inliers\n",
    "            print(f\"  [Iter {it}] New Best: {count}/{total_boards} inliers.\")\n",
    "\n",
    "    print(f\"\\nRANSAC Complete. Kept {len(best_inliers_idx)} boards.\")\n",
    "\n",
    " # --- FINAL REFINEMENT ---\n",
    "    print(\">>> Final Optimization using Inliers...\")\n",
    "    final_obj = [objpoints[k] for k in best_inliers_idx]\n",
    "    final_L   = [imgpoints_L[k] for k in best_inliers_idx]\n",
    "    final_R   = [imgpoints_R[k] for k in best_inliers_idx]\n",
    "\n",
    "    final_criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 1e-5)\n",
    "\n",
    "    # CRITICAL CHANGE: \n",
    "    # 1. We REMOVE 'cv2.CALIB_FIX_INTRINSIC'. \n",
    "    #    This allows the focal length to change to fit the stereo geometry.\n",
    "    # 2. We ADD 'cv2.CALIB_FIX_ASPECT_RATIO'.\n",
    "    #    This keeps fx and fy linked, preventing wild distortions.\n",
    "    # 3. We ADD 'cv2.CALIB_USE_INTRINSIC_GUESS'.\n",
    "    #    This tells it to start with the Mono results (1128) but improve them.\n",
    "    \n",
    "    # We add CALIB_FIX_PRINCIPAL_POINT. \n",
    "    # This prevents the center of the image from drifting, \n",
    "    # forcing the solver to adjust ONLY the Focal Length and Baseline.\n",
    "    final_flags = cv2.CALIB_USE_INTRINSIC_GUESS | \\\n",
    "                  cv2.CALIB_FIX_ASPECT_RATIO | \\\n",
    "                  cv2.CALIB_ZERO_TANGENT_DIST | \\\n",
    "                  cv2.CALIB_FIX_K3 | \\\n",
    "                  cv2.CALIB_FIX_PRINCIPAL_POINT \n",
    "\n",
    "    retS, K1, D1, K2, D2, R, T, E, F = cv2.stereoCalibrate(\n",
    "        final_obj, final_L, final_R,\n",
    "        K1, D1, K2, D2,\n",
    "        img_shape,\n",
    "        criteria=final_criteria,\n",
    "        flags=final_flags \n",
    "    )\n",
    "\n",
    "    print(f\"\\nFINAL STEREO RMS: {retS:.4f} px\")\n",
    "    print(f\"Baseline (T x): {T[0][0]:.4f}\")\n",
    "    print(f\"New Focal Length (fx): {K1[0][0]:.4f}\")\n",
    "\n",
    "    # --- RECTIFICATION & EXPORT ---\n",
    "    print(\"\\n>>> Calculating Rectification Transforms...\")\n",
    "    R1, R2, P1, P2, Q, roi1, roi2 = cv2.stereoRectify(\n",
    "        K1, D1, K2, D2, img_shape, R, T, flags=cv2.CALIB_ZERO_DISPARITY, alpha=1\n",
    "    )\n",
    "\n",
    "    # EXPORT TO KITTI FILE\n",
    "    save_kitti_format(\"calib_cam_to_cam.txt\", img_shape, K1, D1, K2, D2, R, T, R1, R2, P1, P2)\n",
    "\n",
    "    # --- VISUALIZATION ---\n",
    "    print(\"\\n>>> Visualizing Rectification...\")\n",
    "    \n",
    "    map1x, map1y = cv2.initUndistortRectifyMap(K1, D1, R1, P1, img_shape, cv2.CV_32FC1)\n",
    "    map2x, map2y = cv2.initUndistortRectifyMap(K2, D2, R2, P2, img_shape, cv2.CV_32FC1)\n",
    "\n",
    "    for f_left, f_right in zip(left_files, right_files):\n",
    "        imgL = cv2.imread(f_left)\n",
    "        imgR = cv2.imread(f_right)\n",
    "        if imgL is None or imgR is None: continue\n",
    "\n",
    "        rectL = cv2.remap(imgL, map1x, map1y, cv2.INTER_LINEAR)\n",
    "        rectR = cv2.remap(imgR, map2x, map2y, cv2.INTER_LINEAR)\n",
    "\n",
    "        combined = np.hstack((rectL, rectR))\n",
    "        for y in range(0, combined.shape[0], 50):\n",
    "            cv2.line(combined, (0, y), (combined.shape[1], y), (0, 255, 0), 1)\n",
    "\n",
    "        preview = cv2.resize(combined, None, fx=0.5, fy=0.5)\n",
    "        cv2.putText(preview, f\"RMS: {retS:.3f}\", (30,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow(\"Rectification (RANSAC)\", preview)\n",
    "        if cv2.waitKey(0) == 27: break\n",
    "    \n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
